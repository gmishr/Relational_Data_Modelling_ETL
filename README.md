# Sparkify Database
## Introduction:
A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. So in this Sparkify database we are loading two source files song data and log data into one fact table and four dimension tables using ETL written in python. So that analytics team can easily access normalized data to get insights from that data which will help business to take decisions.

## Source Dataset:
### Song Dataset: 
Each file is in JSON format and contains metadata about a song and the artist of that song.The files are partitioned by the first three letters of each song's track ID. For example, here are filepaths to two files in this dataset.
File Examples: 
song_data/A/B/C/TRABCEI128F424C983.json
song_data/A/A/B/TRAABJL12903CDCF1A.json

### Log Dataset: 
Dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations. This file partitioned by year and month.
File Examples:
log_data/2018/11/2018-11-12-events.json
log_data/2018/11/2018-11-13-events.json

## Database Schema:
### Database:
Name : Sparkify
In this database we have one fact table and four dimension tables which are in relation with fact table in star schema with primary key.

#### Fact Table:
Name : songplays 
In this table we loading log data associated with song plays and it contains below columns.
songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent

#### Dimension Tables:
Name : users 
In this table we are loading data related to user which is getting loaded from Log Dataset and it contains below columns.
user_id, first_name, last_name, gender, level

Name : songs
In this table we are loading data related to song which is getting loaded from song Dataset and it contains below columns.
song_id, title, artist_id, year, duration

Name : artists
In this table we are loading data related to artist which is getting loaded from song Dataset and it contains below columns.
artist_id, name, location, latitude, longitude

Name : time 
In this table we are loading data related to timestamp and all columns in this table are extracted from one column timestamp of log dataset and it contains below columns.
start_time, hour, day, week, month, year, weekday

## Project Code Files:
### sql_queries.py:
This file contains all SQL queries which are required to create tables, drop tables, insert data into tables, select data from tables which we are using to load data in all tables from source dataset and extract data from target tables.

### create_tables.py:
This file contains python script which is used to create database and tables by importing queries written in  sql_queries.py script.

### etl.py:
This script code is written to reads and processes files from song_data and log_data and loads them into fact and dimension tables with help of insert and select quries written in sql_queries.py.

## Commands:
### Command to install required packages:
#### to install psycopg2 package:
pip install psycopg2

#### to install panadas package:
pip install pandas

### Command to create Database and Tables:
python create_tables.py

### Command to load data into tables from source dataset:
python etl.py